{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae25be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42aa7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the batch_size\n",
    "batch_size = 64\n",
    "#Defining the transforms for the data\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "#Getting the data\n",
    "train_data = datasets.MNIST('data',download=True,\n",
    "                           train = True, transform = transform)\n",
    "\n",
    "#Preparing the dataloader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
    "                         shuffle = True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55862001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "i = 7\n",
    "img=np.squeeze(images[i])\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img,cmap='gray')\n",
    "ax.set_title(labels[i])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874be436",
   "metadata": {},
   "source": [
    "### The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd6e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,hidden_dim*4)\n",
    "        self.fc2 = nn.Linear(hidden_dim*4,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim,output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = x.view(-1,28*28)\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65fa389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim*4)\n",
    "        self.fc4 = nn.Linear(hidden_dim*4,output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        out = torch.tanh(self.fc4(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "387bb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hyperparameters.\n",
    "\n",
    "#Discriminator Hyperparameters\n",
    "d_input_size = 784\n",
    "d_output_size = 1\n",
    "d_hidden_dim = 32\n",
    "\n",
    "#Generator Hyperparameters\n",
    "g_input = 100\n",
    "g_output = 784\n",
    "g_hidden_dim  = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246c3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "\n",
      "Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=784, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "disc = Discriminator(d_input_size,d_hidden_dim,d_output_size)\n",
    "gen = Generator(g_input,g_hidden_dim,g_output)\n",
    "\n",
    "print(disc)\n",
    "print()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02296896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "def real_loss(d_out,smooth = False):\n",
    "    size = d_out.size(0)\n",
    "\n",
    "    if smooth:\n",
    "        labels = torch.ones(size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(size) \n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(d_out.squeeze(),labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss (d_out):\n",
    "    labels = torch.zeros(d_out.shape[0])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(d_out.squeeze(),labels)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ef3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Optimizers\n",
    "lr = 0.002\n",
    "d_optimizer = optim.Adam(disc.parameters(),lr)\n",
    "g_optimizer = optim.Adam(gen.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79e98f",
   "metadata": {},
   "source": [
    "## Training the 2 models.\n",
    "\n",
    "1. First, we need to train the Discriminator model, To do that, \n",
    "    * We first need to train the discriminator on the real images\n",
    "    * Generate Fake images\n",
    "    * Train the model on fake images with labels = 0\n",
    "    * Add the real and fake losses\n",
    "    * Perform Back propagation\n",
    "<br>\n",
    "\n",
    "2. With the trained model in our hand, it is now time to train the Generator model.\n",
    "    *  We generate the fake images\n",
    "    * Compute the discriminator loss with the labels = 1\n",
    "    * back_propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3438e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Discriminator loss:1.3881| generator_loss:0.6191\n",
      "Epoch 1/100 | Discriminator loss:1.3228| generator_loss:0.6715\n",
      "Epoch 2/100 | Discriminator loss:1.3231| generator_loss:0.6834\n",
      "Epoch 2/100 | Discriminator loss:1.3120| generator_loss:0.6868\n",
      "Epoch 3/100 | Discriminator loss:1.3125| generator_loss:0.6839\n",
      "Epoch 3/100 | Discriminator loss:1.3194| generator_loss:0.6880\n",
      "Epoch 4/100 | Discriminator loss:1.3146| generator_loss:0.6884\n",
      "Epoch 4/100 | Discriminator loss:1.3153| generator_loss:0.6873\n",
      "Epoch 5/100 | Discriminator loss:1.3065| generator_loss:0.6866\n",
      "Epoch 5/100 | Discriminator loss:1.3106| generator_loss:0.6995\n",
      "Epoch 6/100 | Discriminator loss:1.3182| generator_loss:0.6918\n",
      "Epoch 6/100 | Discriminator loss:1.3097| generator_loss:0.6868\n",
      "Epoch 7/100 | Discriminator loss:1.3088| generator_loss:0.6843\n",
      "Epoch 7/100 | Discriminator loss:1.3216| generator_loss:0.6779\n",
      "Epoch 8/100 | Discriminator loss:1.3250| generator_loss:0.6872\n",
      "Epoch 8/100 | Discriminator loss:1.3226| generator_loss:0.6806\n",
      "Epoch 9/100 | Discriminator loss:1.3207| generator_loss:0.6844\n",
      "Epoch 9/100 | Discriminator loss:1.3212| generator_loss:0.6828\n",
      "Epoch 10/100 | Discriminator loss:1.3199| generator_loss:0.6802\n",
      "Epoch 10/100 | Discriminator loss:1.3204| generator_loss:0.6809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mw:\\The Actual Work\\Repo\\GitHub Repositories\\Generative-Adversarial-Networks-using-PyTorch\\MNIST GANs\\MNIST_GAN.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000012?line=11'>12</a>\u001b[0m gen\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000012?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000012?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_i, (real_images,_) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000012?line=15'>16</a>\u001b[0m         batch_size \u001b[39m=\u001b[39m real_images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000012?line=17'>18</a>\u001b[0m         \u001b[39m#rescaling the images:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/datasets/mnist.py?line=141'>142</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/datasets/mnist.py?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/datasets/mnist.py?line=144'>145</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/datasets/mnist.py?line=146'>147</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/datasets/mnist.py?line=147'>148</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=126'>127</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=127'>128</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=128'>129</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=129'>130</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=132'>133</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=133'>134</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/transforms.py?line=134'>135</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torchvision\\transforms\\functional.py:151\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/functional.py?line=148'>149</a>\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/functional.py?line=149'>150</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[1;32m--> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/functional.py?line=150'>151</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], \u001b[39mlen\u001b[39;49m(pic\u001b[39m.\u001b[39;49mgetbands()))\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/functional.py?line=151'>152</a>\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torchvision/transforms/functional.py?line=152'>153</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "print_every = 500\n",
    "\n",
    "samples=[]\n",
    "losses=[]\n",
    "\n",
    "sample_size = 16\n",
    "fixed_z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "disc.train()\n",
    "gen.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_i, (real_images,_) in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        #rescaling the images:\n",
    "        real_images = real_images*2 -1\n",
    "\n",
    "        #________________Training the Discriminator________________________________\n",
    "\n",
    "        z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = gen(z)\n",
    "    \n",
    "    # Generating the Real and Fake losses\n",
    "        d_real = disc(real_images)\n",
    "        d_fake = disc(fake_images)\n",
    "\n",
    "        r_loss = real_loss(d_real.squeeze(),smooth=True)\n",
    "        f_loss = fake_loss(d_fake.squeeze())\n",
    "\n",
    "        d_loss = r_loss+f_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        #_______________Training the Generator_________________\n",
    "\n",
    "        z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = gen(z)\n",
    "\n",
    "        d_fake = disc(fake_images)\n",
    "        g_loss = real_loss(d_fake)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        #_______________Printing the stats_______________\n",
    "        if batch_i %print_every ==0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} | Discriminator loss:{d_loss.item():.4f}| generator_loss:{g_loss.item():.4f}')\n",
    "    \n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "\n",
    "    samples_z = gen(fixed_z)\n",
    "    samples.append(samples_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f52257",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_losses = [x[0] for x in losses]\n",
    "gen_losses = [x[1] for x in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e054e05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(disc_losses,label='Discriminator Losses')\n",
    "ax.plot(gen_losses,label='Generator Losses')\n",
    "ax.set_ybound(lower=0.0, upper = 5.0)\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3783c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_observed = list(range(epochs))[::4]\n",
    "epochs_observed.append(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67bf996",
   "metadata": {},
   "source": [
    "We have 64 digits in each sample. We are going to observe the first 5 in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad16064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch,samples):\n",
    "    fig,axes = plt.subplots(figsize=(14,14), nrows=1, ncols=5, sharey=True)\n",
    "    for ax,img in zip(axes.flatten(),samples[epoch]):\n",
    "        img = img.detach().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape(28,28), cmap='Greys') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d4f31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for epoch in epochs_observed:\n",
    "#     view_samples(epoch,samples)\n",
    "view_samples(8,samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ff0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
