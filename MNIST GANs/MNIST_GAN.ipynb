{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae25be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42aa7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the batch_size\n",
    "batch_size = 64\n",
    "#Defining the transforms for the data\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "#Getting the data\n",
    "train_data = datasets.MNIST(\n",
    "    'data',\n",
    "    download=True,\n",
    "    train = True,\n",
    "    transform = transform\n",
    "    )\n",
    "\n",
    "#Preparing the dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55862001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "i = 7\n",
    "img=np.squeeze(images[i])\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img,cmap='gray')\n",
    "ax.set_title(labels[i])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874be436",
   "metadata": {},
   "source": [
    "### The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd6e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,hidden_dim*4)\n",
    "        self.fc2 = nn.Linear(hidden_dim*4,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim,output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = x.view(-1,28*28)\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fa389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,hidden_dim*2)\n",
    "        self.fc3 = nn.Linear(hidden_dim*2,hidden_dim*4)\n",
    "        self.fc4 = nn.Linear(hidden_dim*4,output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        out = torch.tanh(self.fc4(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387bb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hyperparameters.\n",
    "\n",
    "#Discriminator Hyperparameters\n",
    "d_input_size = 784\n",
    "d_output_size = 1\n",
    "d_hidden_dim = 32\n",
    "\n",
    "#Generator Hyperparameters\n",
    "g_input = 100\n",
    "g_output = 784\n",
    "g_hidden_dim  = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246c3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "\n",
      "Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=784, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "disc = Discriminator(d_input_size,d_hidden_dim,d_output_size).cuda()\n",
    "gen = Generator(g_input,g_hidden_dim,g_output).cuda()\n",
    "\n",
    "print(disc)\n",
    "print()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02296896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "def real_loss(d_out,smooth = False):\n",
    "    size = d_out.size(0)\n",
    "\n",
    "    if smooth:\n",
    "        labels = torch.ones(size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(size) \n",
    "\n",
    "    labels=labels.cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(d_out.squeeze(),labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss (d_out):\n",
    "    labels = torch.zeros(d_out.shape[0])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    labels=labels.cuda()\n",
    "    loss = criterion(d_out.squeeze(),labels)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ef3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Optimizers\n",
    "lr = 0.002\n",
    "d_optimizer = optim.Adam(disc.parameters(),lr)\n",
    "g_optimizer = optim.Adam(gen.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79e98f",
   "metadata": {},
   "source": [
    "## Training the 2 models.\n",
    "\n",
    "1. First, we need to train the Discriminator model, To do that, \n",
    "    * We first need to train the discriminator on the real images\n",
    "    * Generate Fake images\n",
    "    * Train the model on fake images with labels = 0\n",
    "    * Add the real and fake losses\n",
    "    * Perform Back propagation\n",
    "<br>\n",
    "\n",
    "2. With the trained model in our hand, it is now time to train the Generator model.\n",
    "    *  We generate the fake images\n",
    "    * Compute the discriminator loss with the labels = 1\n",
    "    * back_propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3438e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Discriminator loss:1.0927| generator_loss:1.0883\n",
      "Epoch 1/100 | Discriminator loss:1.0874| generator_loss:1.0715\n",
      "Epoch 2/100 | Discriminator loss:1.0980| generator_loss:1.1025\n",
      "Epoch 2/100 | Discriminator loss:1.0891| generator_loss:1.1022\n",
      "Epoch 3/100 | Discriminator loss:1.0784| generator_loss:1.1079\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mw:\\The Actual Work\\Repo\\GitHub Repositories\\Generative-Adversarial-Networks-using-PyTorch\\MNIST GANs\\MNIST_GAN.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000011?line=30'>31</a>\u001b[0m     fake_images \u001b[39m=\u001b[39m fake_images\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000011?line=32'>33</a>\u001b[0m \u001b[39m# Generating the Real and Fake losses\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000011?line=33'>34</a>\u001b[0m     d_real \u001b[39m=\u001b[39m disc(real_images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000011?line=34'>35</a>\u001b[0m     d_fake \u001b[39m=\u001b[39m disc(fake_images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000011?line=36'>37</a>\u001b[0m     r_loss \u001b[39m=\u001b[39m real_loss(d_real\u001b[39m.\u001b[39msqueeze(),smooth\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mw:\\The Actual Work\\Repo\\GitHub Repositories\\Generative-Adversarial-Networks-using-PyTorch\\MNIST GANs\\MNIST_GAN.ipynb Cell 5'\u001b[0m in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000004?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000004?line=15'>16</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x), \u001b[39m0.2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000004?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000004?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x), \u001b[39m0.2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/w%3A/The%20Actual%20Work/Repo/GitHub%20Repositories/Generative-Adversarial-Networks-using-PyTorch/MNIST%20GANs/MNIST_GAN.ipynb#ch0000004?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/dropout.py?line=56'>57</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/modules/dropout.py?line=57'>58</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\nn\\functional.py:1279\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/functional.py?line=1276'>1277</a>\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/functional.py?line=1277'>1278</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[1;32m-> <a href='file:///c%3A/Users/akhil/anaconda3/envs/data/lib/site-packages/torch/nn/functional.py?line=1278'>1279</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "print_every = 500\n",
    "\n",
    "samples=[]\n",
    "losses=[]\n",
    "\n",
    "sample_size = 16\n",
    "fixed_z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "fixed_z = fixed_z.cuda()\n",
    "\n",
    "disc.train()\n",
    "gen.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_i, (real_images,_) in enumerate(train_loader):\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        #rescaling the images:\n",
    "        real_images = real_images*2 -1\n",
    "        \n",
    "        #moving real_images to GPU\n",
    "        real_images=real_images.cuda()\n",
    "\n",
    "        #________________Training the Discriminator________________________________\n",
    "\n",
    "        z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        z = z.cuda()\n",
    "        fake_images = gen(z)\n",
    "        fake_images = fake_images.cuda()\n",
    "    \n",
    "    # Generating the Real and Fake losses\n",
    "        d_real = disc(real_images)\n",
    "        d_fake = disc(fake_images)\n",
    "\n",
    "        r_loss = real_loss(d_real.squeeze(),smooth=True)\n",
    "        f_loss = fake_loss(d_fake.squeeze())\n",
    "\n",
    "        d_loss = r_loss+f_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        #_______________Training the Generator_________________\n",
    "\n",
    "        z = np.random.uniform(-1,1,size=(batch_size, g_input))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        z = z.cuda()\n",
    "        fake_images = gen(z)\n",
    "        fake_images = fake_images.cuda()\n",
    "\n",
    "        d_fake = disc(fake_images.detach())\n",
    "        g_loss = real_loss(d_fake)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        #_______________Printing the stats_______________\n",
    "        if batch_i %print_every ==0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} | Discriminator loss:{d_loss.item():.4f}| generator_loss:{g_loss.item():.4f}')\n",
    "    \n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "\n",
    "    samples_z = gen(fixed_z)\n",
    "    samples.append(samples_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f52257",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_losses = [x[0] for x in losses]\n",
    "gen_losses = [x[1] for x in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e054e05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(disc_losses,label='Discriminator Losses')\n",
    "ax.plot(gen_losses,label='Generator Losses')\n",
    "ax.set_ybound(lower=0.0, upper = 5.0)\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3783c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_observed = list(range(epochs))[::4]\n",
    "epochs_observed.append(39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67bf996",
   "metadata": {},
   "source": [
    "We have 64 digits in each sample. We are going to observe the first 5 in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad16064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch,samples):\n",
    "    fig,axes = plt.subplots(figsize=(14,14), nrows=1, ncols=5, sharey=True)\n",
    "    for ax,img in zip(axes.flatten(),samples[epoch]):\n",
    "        img = img.detach().numpy()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape(28,28), cmap='Greys') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d4f31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x1008 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for epoch in epochs_observed:\n",
    "#     view_samples(epoch,samples)\n",
    "view_samples(8,samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ff0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
